{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIF831sr0y8p"
   },
   "source": [
    "# Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "  \"langchain==1.0.8\" \\\n",
    "  \"langchain-community==0.4.1\" \\\n",
    "  \"langchain-core==1.1.0\" \\\n",
    "  \"langchain-text-splitters==1.0.0\" \\\n",
    "  \"chromadb==1.3.5\" \\\n",
    "  \"llama-cpp-python==0.3.16\" \\\n",
    "  \"sentence-transformers==5.1.2\" \\\n",
    "  \"scikit-learn==1.7.2\" \\\n",
    "  \"numpy==2.1.0\" \\\n",
    "  \"rouge-score==0.1.2\" \\\n",
    "  \"nltk==3.9.2\" \\\n",
    "  \"tqdm==4.67.1\" \\\n",
    "  \"huggingface-hub==0.36.0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTFd-tHB1J-I"
   },
   "source": [
    "# Downloading the ollama mistral 7b instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLhKMaJxSwx0",
    "outputId": "89ce3134-3389-4f73-8faa-4bec3525778e"
   },
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q8_0.gguf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2deM7A_80_Me"
   },
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkDz4zucRocs"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "from llama_cpp import Llama\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VL-zsZ91F3k"
   },
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuZvewewR1a8",
    "outputId": "30dc6af1-6cc8-4c21-f6af-a0a1cd65a79b"
   },
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwBaQcrXW1nd"
   },
   "outputs": [],
   "source": [
    "data_path = \"/content/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqdGlbYF1gKu"
   },
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GN1RFoyvS1d6",
    "outputId": "335fa01b-eaf4-4303-a26f-bc2c1ea44d79"
   },
   "outputs": [],
   "source": [
    "llm = Llama(\n",
    "    model_path=\"mistral-7b-instruct-v0.2.Q8_0.gguf\",\n",
    "    n_ctx=4096,\n",
    "    n_threads=8,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RdYVvxz1kJG"
   },
   "source": [
    "# Donwloading the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "38d5a3b422ba49feaac46ee68ba5d2d4",
      "664d32c6443d4289921cce6c713fbda4",
      "d28c612bfbb648baa4de5004a429edbb",
      "41f3b02b3c7d46438d9a68253d08cf22",
      "40c9f6942384428faca06ac84d7c3b95",
      "264c28953ebc4d62ad8aca15be42337b",
      "86f41315d95842fc8bc6afffb4aa0d45",
      "ce8c2ed9479f41c685f3c4fb5764e814",
      "956c3205cf084e33a28f21e30e49e979",
      "818d091014614d089499b9d4cdd0e10e",
      "7c266628f5824b3ca0e077c8c4c357dc",
      "2565d25f86404abda331195e94f63e76",
      "79455e2e501c49d09d2b5b856af4c260",
      "7c03f7cc60e245c9a2b872632785f500",
      "f93691b1870a40c38b4a55ed8db2d174",
      "be2bef2fd255491280117e7e9ed9e54d",
      "896ec7951e52475aa80ff7dd87da1580",
      "4ee0db7952734facacc6f6836ed55ba0",
      "d536f11f29c547358aea28b469c305f3",
      "8c0d3b980bb945c7b7501c2baebcaa25",
      "2b1d6df8719046d5895ba1b6bea7979b",
      "fbbdc6316b794c0d8db67f8711693280",
      "68ead18f1f734a26955bb3eb1049dfe2",
      "980c7be840e84feeb9bb26741ded100c",
      "0ac899f326174fa29341513d333a670d",
      "2a2c22abcc96437a9d64aaaf5297a065",
      "3740e41420104647b423d4a7d0b28619",
      "056edcba88994636b9ba5ad8b4625bd0",
      "124b460de61f47b699c29c65349245c4",
      "7624212247c4490680c241e6625a9277",
      "34d11c7d654345a8a5fe294846c2ee64",
      "64561469ca9842ab80f7b545eebc5e4f",
      "8de1a79ace1544c1a2840383db49f2f9",
      "1b5e6e1194074c3b9f29bb06eba78f5f",
      "a28d1a22b6354d9884e972a7282d07c3",
      "5f2dc626f75444bebdfbc0bfdccbbc89",
      "3371c5f4aaa94ae0ab98e6ebc927c694",
      "b7a40d7d00a44f5fb1e7f9a6f8613a94",
      "7794e815b9d34602a0f6075530e9ffcf",
      "0689d30d7e094a248dda7cbf768e67b8",
      "927b9a2e4ba342c28f0e0908ee043575",
      "96b808bc5ea7489f99882b1b05408546",
      "b358665489b94e30a3e889844231c712",
      "73638f644c4347228e18e71e147256d2",
      "fb2c92c025564579837e0148ccda2aab",
      "9b53ff9a15e64dffb7c385429db31994",
      "9834a02c7e8a473cb82265fee5b596f1",
      "6bb50de4c71b48ccadbb322bfe18d526",
      "8fa2573c10664440aec6182ac89a88e8",
      "847c6b12812b4602b6fd5af795ae141e",
      "20166ea340394d43b84fe7382ef71be6",
      "c292a528f5af40b8abf93d8d050fe949",
      "e854af32e52c4b2395c953792573b1be",
      "9fabfbfb114d4403a079dac439f3f0af",
      "0834b7fce7b24d2cbffc980b373b35f1",
      "2da4172540044ebc9dc26a14c093631e",
      "62351a3ebc2c425ca716c563f0206abd",
      "aebce25e1f05442dab35d1aef6694799",
      "2cd06ac8bc224408bd341d4909d4fdf3",
      "40664946031d4f61b262608ff11130e1",
      "b9fe7d0eb4b0492a807cf76eb7d5a59e",
      "b6576fdf070945768252ffa2772b859a",
      "021ccf569ff640518b0296fcfdb1925b",
      "022758ee815b4db18a5be2661054a424",
      "5a7aaa70a654447c9afc8fe37c7c8132",
      "831d77f6b0d34e4c847cce636b0bfd8b",
      "bcf54f9e2bd840818b62f192b9379cdc",
      "9b3d69ea82da424d8d2c31a94c527a5a",
      "554834db6e0f49c5b6dd3bfcfd7cb76c",
      "17177a9cdc9340a9af7f0149e221d2cb",
      "10332090ca8f43899d8a2fd644fb3664",
      "987d18429be14fe6b3ba1dd20279bed8",
      "33a976cd64b24a0fad558c1ce15a095c",
      "193936fd45c84af5bfe5d1c77a666cef",
      "6a9b0f5960184fa2846d9150b506a906",
      "d221af2063074e9082c2bf5a93d70b4d",
      "adb0d4e5ea4648cfb706dd76b98c6b80",
      "7d9113c7174b499db99648557914dddd",
      "81125077d4394ce8a9395fcd72def35a",
      "d5663127de2c4d39a57e95df552cba23",
      "de8e3c13f1ed4d13a62d78020f13bd02",
      "6bd55a3ede954e059ba67b0e50b330c4",
      "4d41b99a86f24f1b802aca7cacee0967",
      "5fcbbbe6691c4606922a2c7f4e37c23b",
      "fea92a24965b4e8b8bc85e5e162537ef",
      "2a35bc7750bf48ba9cf64daafc9766a3",
      "40e61adc88bc424d89cd636ee14de17b",
      "6a38a5018af3449fba3cd311ef24ea1b",
      "0f50e7da4ae0416097b3aeb448b02146",
      "738ea4c50b924767aec8b8b9b7f6ea9e",
      "2ac1629ff08b4354b95bc73a41fa0fc2",
      "99f2a65a2f3b432281643ef86dd7567f",
      "2dcfea28b6d34053b4d6de709dbcd335",
      "4b6bf55d81af4e6a855fbabb3e70b0e9",
      "f92d12d2a0354465a3e27282d8d87150",
      "16e22c491fbd4af3a0895caf174c8d10",
      "689cdf4d1ba047faa06f61ede625a9d8",
      "644f6a25809847b8b13476b1f297534d",
      "1f0b512b8e8244259e2542b2fb96aad8",
      "383ee7af4f5d42d9a9ff23ea6452dd2e",
      "88bc3a2b6b9b44e08e24f3ce4fd8204c",
      "b5eaef4ecd50405a9cd8d24f34a05566",
      "8da05fdfb3f44773afdb97559f05641f",
      "21b4cc2cead44dcbb092bf1402af7090",
      "7e34e5df9f094483be36160a883296b0",
      "6341a7e21b3c42b3b847fcade7f4c26d",
      "8d7dc09822ea4f3c8e50ab48ef876f5c",
      "3b58eaa6f185485d857900a7dcdda388",
      "67cc4dd538ab4772803779eef6063989",
      "8a25216316724851bc218cf13511ab7e",
      "5e508ad4006e439388d5afcf72c2a7a1",
      "5169bc7f34b0445e8f93d8a2fb516362",
      "47ac443fb5024436ab3df9a3b665ef3b",
      "e22fa174523c467f83c13c4e5d028ee4",
      "010b7fbec5444231a6f2825fc3a55ea2",
      "27d0d74b0f0a49f386909c2924dcdb03",
      "5e5e1ffb7ab94f2fa128c5c3ddb84259",
      "5026b3a44b9e4a02b4e7eaa17718bae9",
      "3df3ef24700443319246466a5bee6459",
      "07e6035fd2f44725b7a529bb05fb19f2",
      "6eed08439ebb480d9a42572630faecb3"
     ]
    },
    "id": "QAE3qkmmXvhv",
    "outputId": "c9375d46-8ec0-46ce-f6b6-66e02848f0c9"
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QUDkdW91qRr"
   },
   "source": [
    "# loading the text splitter for spilliting the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHoQdVsKXkLd"
   },
   "outputs": [],
   "source": [
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJwdd3qt12a2"
   },
   "source": [
    "# Loading the documents and spilliting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mx3vjHwMYd5R"
   },
   "outputs": [],
   "source": [
    "chunks_dict = {}\n",
    "speeches = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzxHUcx8R1Ym"
   },
   "outputs": [],
   "source": [
    "for speech in speeches:\n",
    "  if os.path.splitext(speech)[1] == \".txt\":\n",
    "    loader = TextLoader(os.path.join(data_path, speech))\n",
    "    documents = loader.load()\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    chunks_dict[speech] = chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFgZfuwz1_7q"
   },
   "source": [
    "# Converting the chunks into embeddings and storing them in chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OpaYebmYKnk"
   },
   "outputs": [],
   "source": [
    "chroma_store = Chroma.from_documents(\n",
    "    documents= [chunk for chunk_list in list(chunks_dict.values()) for chunk in chunk_list],\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lL25ZoDe2H4y"
   },
   "source": [
    "# Preparing a prompt template to generate input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7tA03dmbdyo"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You must answer the question strictly and exclusively using the information provided in the context below.\n",
    "\n",
    "If the context does NOT contain information that directly answers the question, reply exactly with:\n",
    "\"No relevant information available.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE0HQ46P2PvN"
   },
   "source": [
    "# Testing everything:\n",
    "\n",
    "\n",
    "*   sending query to get 2 relevant chunks from db.\n",
    "*   passing the query and the chunk to the model to generate output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nldntltaWto",
    "outputId": "c6d22751-5f9d-4e5c-8bc5-ec1a0d550792"
   },
   "outputs": [],
   "source": [
    "query = \"How does Ambedkar characterize the Hindu-Muslim problem?\"\n",
    "results = chroma_store.similarity_search(query, k=2)\n",
    "context = \"\"\n",
    "for r in results:\n",
    "    print(\"\\n--- RESULT ---\")\n",
    "    print(r.metadata[\"source\"].split(\"/\")[-1])\n",
    "    print(r.page_content)\n",
    "    context += r.page_content + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGH8-ifIVBRN"
   },
   "outputs": [],
   "source": [
    "inp = prompt.format(\n",
    "    question=query,\n",
    "    context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn8uylRut9sJ"
   },
   "outputs": [],
   "source": [
    "response = llm(\n",
    "    inp,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYf_hCuQxHuD",
    "outputId": "3969890d-5b23-47fb-82b1-a90a92c4fa59"
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_xHDvSOuCBa",
    "outputId": "c3b4efc6-c376-4712-c610-f309f95bb667"
   },
   "outputs": [],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3Dx4VX02swE"
   },
   "source": [
    "# function to generate output directly by the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8M5Pt6Bw15l"
   },
   "outputs": [],
   "source": [
    "def get_response(query):\n",
    "  results = chroma_store.similarity_search(query, k=2)\n",
    "  context = \"\"\n",
    "  fetched_documents = []\n",
    "  for r in results:\n",
    "    context += r.page_content + \"\\n\"\n",
    "    fetched_documents.append(r.metadata[\"source\"].split(\"/\")[-1])\n",
    "\n",
    "  inp =  prompt.format(\n",
    "    question=query,\n",
    "    context=context\n",
    ")\n",
    "  response = llm(\n",
    "    inp,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7)\n",
    "\n",
    "  output = response[\"choices\"][0][\"text\"]\n",
    "  return output, fetched_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJbDRAPk3jEq",
    "outputId": "23fc3057-4597-4905-beca-5386afe6ee37"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(get_response(\"How does Ambedkar define social democracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrAL7_nFQOyt"
   },
   "source": [
    "# **Evaluating the whole pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h3Yp-GAQhTt"
   },
   "source": [
    "# For evaluating relevent chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyMj0-piSFk_"
   },
   "outputs": [],
   "source": [
    "def recall(retrieved, truth):\n",
    "  if len(truth) == 0 or len(retrieved) == 0:\n",
    "        return 0.0\n",
    "  hits = sum(1 for item in retrieved if item in truth)\n",
    "  return hits / len(truth)\n",
    "\n",
    "\n",
    "def precision(retrieved, truth):\n",
    "    if len(truth) == 0 or len(retrieved) == 0:\n",
    "        return 0.0\n",
    "    hits = sum(1 for item in retrieved if item in truth)\n",
    "    return hits / len(retrieved)\n",
    "\n",
    "\n",
    "def mrr(retrieved, truth):\n",
    "    for idx, item in enumerate(retrieved):\n",
    "        if item in truth:\n",
    "            return 1.0 / (idx + 1)\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap3ZtUkOQm5J"
   },
   "source": [
    "# For evaluaing model's answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZsZ0eHxRjxe"
   },
   "outputs": [],
   "source": [
    "rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "def rouge_f1_score(reference, generated):\n",
    "    return rouge.score(reference, generated)['rougeL'].fmeasure\n",
    "\n",
    "def cosine_score(reference, generated):\n",
    "    emb_reference = embeddings.embed_query(reference)\n",
    "    emb_generated = embeddings.embed_query(generated)\n",
    "    return cosine_similarity([emb_reference], [emb_generated])[0][0]\n",
    "\n",
    "\n",
    "def bleu_score(reference, generated):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return sentence_bleu([reference.split()], generated.split(), smoothing_function=smoothie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8IKAFqyRin2"
   },
   "source": [
    "# Running it on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvLO_F10RoZl"
   },
   "outputs": [],
   "source": [
    "with open(\"data/test_dataset.json\", \"r\") as f:\n",
    "    test_dataset_dict = json.load(f)\n",
    "    test_dataset = test_dataset_dict[\"test_questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_ghZbCKUCHe",
    "outputId": "3db7cd93-e458-48ec-db44-477bdf8e8c08"
   },
   "outputs": [],
   "source": [
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25X8gPSVlH77"
   },
   "outputs": [],
   "source": [
    "test_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMALOOlvgqFY",
    "outputId": "6585c55d-4b0a-43cd-c1b0-7bee453b0036"
   },
   "outputs": [],
   "source": [
    "total_recall = 0\n",
    "total_precision = 0\n",
    "total_mrr = 0\n",
    "\n",
    "total_rouge_f1_score = 0\n",
    "total_cosine_score = 0\n",
    "total_bleu_score = 0\n",
    "\n",
    "for idx, test_item in tqdm(enumerate(test_dataset), total=len(test_dataset)):\n",
    "\n",
    "  query = test_item['question']\n",
    "  correct_answer = test_item['ground_truth']\n",
    "  correct_docs = test_item['source_documents']\n",
    "  isAnswerable = test_item['answerable']\n",
    "\n",
    "  output, docs = get_response(query)\n",
    "\n",
    "  #evaluating retrived documents\n",
    "  current_recall = recall(docs, correct_docs)\n",
    "  current_precision = precision(docs, correct_docs)\n",
    "  current_mrr = mrr(docs, correct_docs)\n",
    "\n",
    "  total_recall += current_recall\n",
    "  total_precision += current_precision\n",
    "  total_mrr += current_mrr\n",
    "\n",
    "  #evaluating model's output\n",
    "  current_rouge_f1_score = rouge_f1_score(correct_answer, output)\n",
    "  current_cosine_score = cosine_score(correct_answer, output)\n",
    "  current_bleu_score = bleu_score(correct_answer, output)\n",
    "\n",
    "  total_rouge_f1_score += current_rouge_f1_score\n",
    "  total_cosine_score += current_cosine_score\n",
    "  total_bleu_score += current_bleu_score\n",
    "\n",
    "  test_results.append({\n",
    "      \"id\" : idx+1,\n",
    "      \"recall\" : current_recall,\n",
    "      \"precision\" : current_precision,\n",
    "      \"MRR\" : current_mrr,\n",
    "      \"ROUGE-L Score\" : current_rouge_f1_score,\n",
    "      \"Cosine Similarity\" : current_cosine_score,\n",
    "      \"BLEU Score\" : current_bleu_score,\n",
    "      \"question\" : query,\n",
    "      \"correct answer\" : correct_answer,\n",
    "      \"model output\" : output\n",
    "\n",
    "  })\n",
    "\n",
    "  tqdm.write(f\"\\n\\nTest Set {idx+1}\")\n",
    "  tqdm.write(f\"Current Recall: {current_recall}\")\n",
    "  tqdm.write(f\"Current Precision: {current_precision}\")\n",
    "  tqdm.write(f\"Current MRR: {current_mrr}\")\n",
    "  tqdm.write(\"\\n\")\n",
    "  tqdm.write(f\"Current Rouge F1 Score: {current_rouge_f1_score}\")\n",
    "  tqdm.write(f\"Current Cosine Score: {current_cosine_score}\")\n",
    "  tqdm.write(f\"Current Bleu Score: {current_bleu_score}\")\n",
    "\n",
    "  tqdm.write(f\"Question: {query}\")\n",
    "  tqdm.write(f\"Correct Answer: {correct_answer}\")\n",
    "  tqdm.write(f\"Model Output: {output}\")\n",
    "\n",
    "print(\"Average Recall:\", (total_recall/len(test_dataset)))\n",
    "print(\"Average Precision:\", (total_precision/len(test_dataset)))\n",
    "print(\"Average MRR:\", (total_mrr/len(test_dataset)))\n",
    "\n",
    "print(\"Average Rouge F1 Score:\", (total_rouge_f1_score/len(test_dataset)))\n",
    "print(\"Average Cosine Score:\", (total_cosine_score/len(test_dataset)))\n",
    "print(\"Average Bleu Score:\", (total_bleu_score/len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrrRS6EfguvK"
   },
   "outputs": [],
   "source": [
    "with open(\"test_results.json\", \"w\") as f:\n",
    "    json.dump(test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRQeVW5uyMYL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
